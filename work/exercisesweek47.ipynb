{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c0b63f",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html exercisesweek47.do.txt  -->\n",
    "<!-- dom:TITLE: Exercise week 47 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb10d9d",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Exercise week 47\n",
    "**November 18-22, 2024**\n",
    "\n",
    "Date: **Deadline is Friday November 22 at midnight**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90add8",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Overarching aims of the exercises this week\n",
    "\n",
    "The exercise set this week is meant as a summary of many of the\n",
    "central elements in various machine learning algorithms, with a slight\n",
    "bias towards deep learning methods and their training. You don't need to answer all questions.\n",
    "\n",
    "The last weekly exercise (week 48) is a general course survey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a2f02b",
   "metadata": {},
   "source": [
    "Answers are in\n",
    "> this format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3ae78",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 1: Linear and logistic regression methods\n",
    "\n",
    "1. What is the main difference between ordinary least squares and Ridge regression?\n",
    "\n",
    "> The addition of a regularization parameter $\\lambda$ (OLS is plain MSE for the cost function, Ridge is MSE $+ \\lambda I$)\n",
    "\n",
    "2. Which kind of data set would you use logistic regression for?\n",
    "\n",
    "> Logistic regression is used for classification problems. \n",
    "\n",
    "3. In linear regression you assume that your output is described by a continuous non-stochastic function $f(x)$. Which is the equivalent function in logistic regression?\n",
    "\n",
    "> A discrete function $f(y | x)$, with an expected value for the output $y$ with a given input $x$\n",
    "\n",
    "4. Can you find an analytic solution to a logistic regression type of problem?\n",
    "\n",
    "> Actually, not sure about this one. Can we?\n",
    "\n",
    "5. What kind of cost function would you use in logistic regression?\n",
    "\n",
    "> Cross entropy is the most common cost function for classification problems, including when using logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755cfd27",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 2: Deep learning\n",
    "\n",
    "1. What is an activation function and discuss the use of an activation function? Explain three different types of activation functions?\n",
    "\n",
    "> The activation function is a function that attempts to model the behaviour of biological neurons, by only passing on input (effectively a $1$) when the input exceeds some treshold. Otherwise it returns $0$. \n",
    ">\n",
    "> The simplest activation function is a step function, with some treshold where any value below the treshold outputs 0, and any above outputs 1. Such a function is not differentiable. Thus sigmoid/logistic functions are more popular, which mimic the behaviour while staying continuous between the \"capped\" values of 0 or 1. The hyperbolic tangent $tanh$ also has this behaviour, and is a popular function for deep neural networks. \n",
    ">\n",
    "> In addition, there is the ReLU family of functions, which return either $0$ or their input $x$ when $x>0$, rather than being capped to 1. This does not really have a biological connection but simply works well experimentally, and avoids problems with vanishing gradients, which is why it is a popular activation function even though nobody seems to be able to really explain why it fits so well\n",
    "\n",
    "2. Describe the architecture of a typical feed forward  Neural Network (NN). \n",
    "\n",
    "> Values are fed forward through layers (hence the name), where they go through multiplication with the layer weights ( $ z = Wx + b $ ) and then the layer activation function ( $ a = $ activation_func $(z)$ ). All nodes are fully connected to the next node.\n",
    "\n",
    "3. You are using a deep neural network for a prediction task. After training your model, you notice that it is strongly overfitting the training set and that the performance on the test isnâ€™t good. What can you do to reduce overfitting?\n",
    "\n",
    "> Tune hyperparemeters, reduce the number of layers, add more data (usually not practical), add regularization (or increase regularization parameters)\n",
    "\n",
    "4. How would you know if your model is suffering from the problem of exploding Gradients?\n",
    "\n",
    "> Overflow warnings in your program. The gradients grow too large for the language to handle and it starts erroring. Can be fixed with batch normalization.\n",
    "\n",
    "5. Can you name and explain a few hyperparameters used for training a neural network?\n",
    "\n",
    "> Some are layer sizes/shapes, activation functions for layers, the final output activation function, all hyperparameters used in gradient descent (since GD is used internally after backpropagation to update weights)\n",
    "\n",
    "6. Describe the architecture of a typical Convolutional Neural Network (CNN)\n",
    "\n",
    "> Similar to a feed forward neural network, but the layers have limited connections, and are not fully connected. Some layers are of different types, like convolutional layers that use dot products on smaller regions of the input layers. Pooling layers downsize their inputs to some smaller output dimension. \n",
    "\n",
    "7. What is the vanishing gradient problem in Neural Networks and how to fix it?\n",
    "\n",
    "> Gradients becoming so small updates to weights are almost insignificant and the model stops improving despite increasing training time. Can be fixed by using ReLU functions.\n",
    "\n",
    "8. When it comes to training an artificial neural network, what could the reason be for why the cost/loss doesn't decrease in a few epochs?\n",
    "\n",
    "> Too low learning rate, or vanishing gradients, so that updates to weights are too small to make an impact.\n",
    "\n",
    "9. How does L1/L2 regularization affect a neural network?\n",
    "\n",
    "> \"It is common to add an extra term to the cost function, proportional to the size of the weights. This is equivalent to constraining the size of the weights, so that they do not grow out of control. Constraining the size of the weights means that the weights cannot grow arbitrarily large to fit the training data, and in this way reduces overfitting.\" - lecture notes\n",
    ">\n",
    "> Same as with Ridge/Lasso, basically.\n",
    "\n",
    "10. What is(are) the advantage(s) of deep learning over traditional methods like linear regression or logistic regression?\n",
    "\n",
    "> Deep learning follows the Universal Approximation Theorem and is in theory able to fit any function by combining simpler functions in some complex fashion. It is in general able to fit more complex relationships in data than linear or logistic regression, for both regression and classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85175b87",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 3: Decision trees and ensemble methods\n",
    "\n",
    "1. Mention some pros and cons when using decision trees\n",
    "\n",
    "> Pros: computationally simple. Easy to set up. Easy to visualize, good for explainable AI tasks.\n",
    ">\n",
    "> Cons: Not as accurate as more complex models. Prone to overfitting. Trees can be biased and don't work as well with unbalanced data.\n",
    "\n",
    "2. How do we grow a tree? And which are the main parameters? \n",
    "\n",
    "> Train the decision tree model by continuously splitting the target feature along the values of the descriptive features using some measure of information gain\n",
    ">\n",
    "> Grow the tree (add nodes) until we hit a stopping criteria. \n",
    ">\n",
    "> Create leaf nodes which represent the predictions we want to make for new query instances after following the tree\n",
    ">\n",
    "> Main parameters are the tuning parameter $\\alpha$, max depth (hyperparameter), measure of information gain per node (usually gini factor or entropy).\n",
    "\n",
    "3. Mention some of the benefits with using ensemble methods (like bagging, random forests and boosting methods)?\n",
    "\n",
    "> Decision trees can have high variance, overfit, and change a lot with small changes to data. Ensemble methods solve those problems.\n",
    "\n",
    "4. Why would you prefer a random forest instead of using Bagging to grow a forest?\n",
    "\n",
    "> Different bagged trees still end up looking similar. Random forest has greater variation.\n",
    "\n",
    "5. What is the basic philosophy behind boosting methods?\n",
    "\n",
    "> Combining many weak classifiers and heavily weighting misclassifications. We iteratively select good classifiers/good parameters and in the end the final model is greater than the sum of its parts (and much better than a weak classifier on its own)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfdfe68",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 4: Optimization part\n",
    "\n",
    "1. Which is the basic mathematical root-finding method behind essentially all gradient descent approaches(stochastic and non-stochastic)? \n",
    "\n",
    "> Newton's method.\n",
    "\n",
    "2. And why don't we use it? Or stated differently, why do we introduce the learning rate as a parameter?\n",
    "\n",
    "> It does not always converge. Very dependent on starting point. Taking small steps on the gradient ensures we are always moving toward some local optima, rather than getting stuck\n",
    "\n",
    "3. What might happen if you set the momentum hyperparameter too close to 1 (e.g., 0.9999) when using an optimizer for the learning rate?\n",
    "\n",
    "> Since momentum modifies the movement direction with the gradient from the previous step, it would completely cancel the current forward movement, or even reverse it.\n",
    "\n",
    "4. Why should we use stochastic gradient descent instead of plain gradient descent?\n",
    "\n",
    "> Faster computation time by avoiding taking the gradient of all data points, instead only needing the gradient over some smaller number of sample points.\n",
    "\n",
    "5. Which parameters would you need to tune when use a stochastic gradient descent approach?\n",
    "\n",
    "> Number of epochs, minibatch size (and learning rate, momentum, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc1b0c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 5: Analysis of results\n",
    "1. How do you assess overfitting and underfitting?\n",
    "\n",
    "> Can look at bias/variance tradeoff. High variance usually indicates overfitting. Otherwise, overfitting will generally give perfect results on training data (0 error), but badly fit new data (test data) and fail to generalize. Underfitting gives high error on all data.\n",
    "\n",
    "2. Why do we divide the data in test and train and/or eventually validation sets?\n",
    "\n",
    "> Check generalization capabilities of a model. Model does not learn the relationships in the train data by never being \"shown\" that data, and must use its inferred \"knowledge\" from other data to predict points that capture the relationship in the test data (as well as in the training data). \n",
    "\n",
    "3. Why would you use resampling methods in the data analysis? Mention some widely popular resampling methods.\n",
    "\n",
    "> To harden your analysis against statistical anomalies, like uneven sampling of certain types of data points. Bootstrap or k-fold cross validation are widely used."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
