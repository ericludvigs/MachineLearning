{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27166338",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Week 34: Introduction to the course, Logistics and Practicalities\n",
    "**Eric Ludvigsen**, Student\n",
    "\n",
    "Date: **Week 34, August 19-23, 2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0fc73",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Here are three possible exercises for week 34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0bd69f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 1: Setting up various Python environments\n",
    "\n",
    "The first exercise here is of a mere technical art. We want you to have \n",
    "* git as a version control software and to establish a user account on a provider like GitHub. Other providers like GitLab etc are equally fine. You can also use the University of Oslo [GitHub facilities](https://www.uio.no/tjenester/it/maskin/filer/versjonskontroll/github.html). \n",
    "\n",
    "* Install various Python packages\n",
    "\n",
    "We will make extensive use of Python as programming language and its\n",
    "myriad of available libraries.  You will find\n",
    "IPython/Jupyter notebooks invaluable in your work.  You can run **R**\n",
    "codes in the Jupyter/IPython notebooks, with the immediate benefit of\n",
    "visualizing your data. You can also use compiled languages like C++,\n",
    "Rust, Fortran etc if you prefer. The focus in these lectures will be\n",
    "on Python.\n",
    "\n",
    "If you have Python installed (we recommend Python3) and you feel\n",
    "pretty familiar with installing different packages, we recommend that\n",
    "you install the following Python packages via **pip** as \n",
    "\n",
    "1. pip install numpy scipy matplotlib ipython scikit-learn sympy pandas pillow \n",
    "\n",
    "For **Tensorflow**, we recommend following the instructions in the text of \n",
    "[Aurelien Geron, Hands‑On Machine Learning with Scikit‑Learn and TensorFlow, O'Reilly](http://shop.oreilly.com/product/0636920052289.do)\n",
    "\n",
    "We will come back to **tensorflow** later. \n",
    "\n",
    "For Python3, replace **pip** with **pip3**.\n",
    "\n",
    "For OSX users we recommend, after having installed Xcode, to\n",
    "install **brew**. Brew allows for a seamless installation of additional\n",
    "software via for example \n",
    "\n",
    "1. brew install python3\n",
    "\n",
    "For Linux users, with its variety of distributions like for example the widely popular Ubuntu distribution,\n",
    "you can use **pip** as well and simply install Python as \n",
    "\n",
    "1. sudo apt-get install python3  (or python for Python2.7)\n",
    "\n",
    "If you don't want to perform these operations separately and venture\n",
    "into the hassle of exploring how to set up dependencies and paths, we\n",
    "recommend two widely used distrubutions which set up all relevant\n",
    "dependencies for Python, namely \n",
    "\n",
    "* [Anaconda](https://docs.anaconda.com/), \n",
    "\n",
    "which is an open source\n",
    "distribution of the Python and R programming languages for large-scale\n",
    "data processing, predictive analytics, and scientific computing, that\n",
    "aims to simplify package management and deployment. Package versions\n",
    "are managed by the package management system **conda**. \n",
    "\n",
    "* [Enthought canopy](https://www.enthought.com/product/canopy/) \n",
    "\n",
    "is a Python\n",
    "distribution for scientific and analytic computing distribution and\n",
    "analysis environment, available for free and under a commercial\n",
    "license.\n",
    "\n",
    "We recommend using **Anaconda** if you are not too familiar with setting paths in a terminal environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "4b83b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviornment is set up hence these packages working\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as skl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03d9f0",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 2: making your own data and exploring scikit-learn\n",
    "\n",
    "We will generate our own dataset for a function $y(x)$ where $x \\in [0,1]$ and defined by random numbers computed with the uniform distribution. The function $y$ is a quadratic polynomial in $x$ with added stochastic noise according to the normal distribution $\\cal {N}(0,1)$.\n",
    "The following simple Python instructions define our $x$ and $y$ values (with 100 data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "2ffabbd8",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823319</td>\n",
       "      <td>4.823722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192135</td>\n",
       "      <td>2.223278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793147</td>\n",
       "      <td>5.505977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476461</td>\n",
       "      <td>2.876920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.930851</td>\n",
       "      <td>5.922537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.495714</td>\n",
       "      <td>3.293497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.943111</td>\n",
       "      <td>6.507975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.300870</td>\n",
       "      <td>2.572539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.757091</td>\n",
       "      <td>4.824440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.872780</td>\n",
       "      <td>5.707134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y\n",
       "0   0.823319  4.823722\n",
       "1   0.192135  2.223278\n",
       "2   0.793147  5.505977\n",
       "3   0.476461  2.876920\n",
       "4   0.930851  5.922537\n",
       "..       ...       ...\n",
       "95  0.495714  3.293497\n",
       "96  0.943111  6.507975\n",
       "97  0.300870  2.572539\n",
       "98  0.757091  4.824440\n",
       "99  0.872780  5.707134\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 100\n",
    "randomness_coeff = 0.2\n",
    "x = np.random.rand(n,1)\n",
    "y = 2.0 + 5*(x*x) + randomness_coeff * np.random.randn(n,1)\n",
    "\n",
    "# fancier display than numpy print\n",
    "results_frame = pd.DataFrame({\"x\":x.flatten(), \"y\":y.flatten()})\n",
    "display(results_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38967294",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. Write your own code (following the examples under the [regression notes](https://compphysics.github.io/MachineLearning/doc/LectureNotes/_build/html/chapter1.html)) for computing the parametrization of the data set fitting a second-order polynomial. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "5cbb64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.823319</td>\n",
       "      <td>0.677854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192135</td>\n",
       "      <td>0.036916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.793147</td>\n",
       "      <td>0.629082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.227015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.866483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495714</td>\n",
       "      <td>0.245733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943111</td>\n",
       "      <td>0.889458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300870</td>\n",
       "      <td>0.090523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.757091</td>\n",
       "      <td>0.573186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.872780</td>\n",
       "      <td>0.761745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2\n",
       "0   1.0  0.823319  0.677854\n",
       "1   1.0  0.192135  0.036916\n",
       "2   1.0  0.793147  0.629082\n",
       "3   1.0  0.476461  0.227015\n",
       "4   1.0  0.930851  0.866483\n",
       "..  ...       ...       ...\n",
       "95  1.0  0.495714  0.245733\n",
       "96  1.0  0.943111  0.889458\n",
       "97  1.0  0.300870  0.090523\n",
       "98  1.0  0.757091  0.573186\n",
       "99  1.0  0.872780  0.761745\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make design matrix\n",
    "P = 3\n",
    "# matrix should correspond to pattern\n",
    "# beta_1 + beta_2*x + beta_3*x^2\n",
    "feature_matrix = np.zeros((n, P))\n",
    "\n",
    "#feature_matrix[:,0] = 1\n",
    "#feature_matrix[:,1] = x[:,0]\n",
    "#feature_matrix[:,2] = x[:,0]**2\n",
    "#feature_matrix[:,3] = x[:,0]**3\n",
    "\n",
    "# automated way of filling matrix\n",
    "for exponent in range(0,P):\n",
    "    feature_matrix[:,exponent] = x[:,0]**exponent\n",
    "\n",
    "print(\"feature matrix\")\n",
    "df = pd.DataFrame(feature_matrix)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "765ed13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix shape:  (100, 3)\n",
      "transposed: (3, 100)\n",
      "X^T X shape: (3, 3)\n",
      "\n",
      "beta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.004780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.923945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  2.004780\n",
       "1  0.001430\n",
       "2  4.923945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y tilde\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.343674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.186826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.103481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.123272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.272629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3.215464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.385770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.450940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.828200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.756821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   5.343674\n",
       "1   2.186826\n",
       "2   5.103481\n",
       "3   3.123272\n",
       "4   6.272629\n",
       "..       ...\n",
       "95  3.215464\n",
       "96  6.385770\n",
       "97  2.450940\n",
       "98  4.828200\n",
       "99  5.756821\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add modelled y to display frame along with absolute error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>y_tilde</th>\n",
       "      <th>y - y_tilde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823319</td>\n",
       "      <td>4.823722</td>\n",
       "      <td>5.343674</td>\n",
       "      <td>-0.519952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192135</td>\n",
       "      <td>2.223278</td>\n",
       "      <td>2.186826</td>\n",
       "      <td>0.036452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793147</td>\n",
       "      <td>5.505977</td>\n",
       "      <td>5.103481</td>\n",
       "      <td>0.402496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476461</td>\n",
       "      <td>2.876920</td>\n",
       "      <td>3.123272</td>\n",
       "      <td>-0.246353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.930851</td>\n",
       "      <td>5.922537</td>\n",
       "      <td>6.272629</td>\n",
       "      <td>-0.350091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.495714</td>\n",
       "      <td>3.293497</td>\n",
       "      <td>3.215464</td>\n",
       "      <td>0.078033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.943111</td>\n",
       "      <td>6.507975</td>\n",
       "      <td>6.385770</td>\n",
       "      <td>0.122205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.300870</td>\n",
       "      <td>2.572539</td>\n",
       "      <td>2.450940</td>\n",
       "      <td>0.121598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.757091</td>\n",
       "      <td>4.824440</td>\n",
       "      <td>4.828200</td>\n",
       "      <td>-0.003761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.872780</td>\n",
       "      <td>5.707134</td>\n",
       "      <td>5.756821</td>\n",
       "      <td>-0.049688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y   y_tilde  y - y_tilde\n",
       "0   0.823319  4.823722  5.343674    -0.519952\n",
       "1   0.192135  2.223278  2.186826     0.036452\n",
       "2   0.793147  5.505977  5.103481     0.402496\n",
       "3   0.476461  2.876920  3.123272    -0.246353\n",
       "4   0.930851  5.922537  6.272629    -0.350091\n",
       "..       ...       ...       ...          ...\n",
       "95  0.495714  3.293497  3.215464     0.078033\n",
       "96  0.943111  6.507975  6.385770     0.122205\n",
       "97  0.300870  2.572539  2.450940     0.121598\n",
       "98  0.757091  4.824440  4.828200    -0.003761\n",
       "99  0.872780  5.707134  5.756821    -0.049688\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# optimal beta is now given by\n",
    "# beta_hat = (X^T X)^-1 X^T y\n",
    "feature_transposed = np.transpose(feature_matrix)\n",
    "print(\"feature matrix shape: \", feature_matrix.shape)\n",
    "print(\"transposed:\", feature_transposed.shape)\n",
    "\n",
    "x_t_x = np.matmul(feature_transposed, feature_matrix)\n",
    "print(\"X^T X shape:\", x_t_x.shape)\n",
    "calc_invert = np.linalg.inv(x_t_x)\n",
    "\n",
    "beta = calc_invert.dot(feature_transposed).dot(y)\n",
    "df = pd.DataFrame(beta)\n",
    "print(\"\\nbeta\")\n",
    "display(df)\n",
    "\n",
    "y_tilde = feature_matrix @ beta\n",
    "df = pd.DataFrame(y_tilde)\n",
    "print(\"y tilde\")\n",
    "display(df)\n",
    "\n",
    "print(\"add modelled y to display frame along with absolute error\")\n",
    "results_frame[\"y_tilde\"] = y_tilde.flatten()\n",
    "results_frame[\"y - y_tilde\"] = y.flatten()-y_tilde.flatten()\n",
    "display(results_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c2bc5",
   "metadata": {},
   "source": [
    "2. Use thereafter **scikit-learn** (see again the examples in the regression slides) and compare with your own code.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "19db55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this cell runs twice in a row (without running the above prediction),\n",
    "# the results are wrong and y_tilde_skl changes - not sure why\n",
    "clf = skl.LinearRegression().fit(feature_matrix, y)\n",
    "ytilde_skl = clf.predict(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "fffbfe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>y_tilde</th>\n",
       "      <th>y - y_tilde</th>\n",
       "      <th>scikit y_tilde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823319</td>\n",
       "      <td>4.823722</td>\n",
       "      <td>5.343674</td>\n",
       "      <td>-0.519952</td>\n",
       "      <td>5.343674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192135</td>\n",
       "      <td>2.223278</td>\n",
       "      <td>2.186826</td>\n",
       "      <td>0.036452</td>\n",
       "      <td>2.186826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.793147</td>\n",
       "      <td>5.505977</td>\n",
       "      <td>5.103481</td>\n",
       "      <td>0.402496</td>\n",
       "      <td>5.103481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.476461</td>\n",
       "      <td>2.876920</td>\n",
       "      <td>3.123272</td>\n",
       "      <td>-0.246353</td>\n",
       "      <td>3.123272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.930851</td>\n",
       "      <td>5.922537</td>\n",
       "      <td>6.272629</td>\n",
       "      <td>-0.350091</td>\n",
       "      <td>6.272629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.495714</td>\n",
       "      <td>3.293497</td>\n",
       "      <td>3.215464</td>\n",
       "      <td>0.078033</td>\n",
       "      <td>3.215464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.943111</td>\n",
       "      <td>6.507975</td>\n",
       "      <td>6.385770</td>\n",
       "      <td>0.122205</td>\n",
       "      <td>6.385770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.300870</td>\n",
       "      <td>2.572539</td>\n",
       "      <td>2.450940</td>\n",
       "      <td>0.121598</td>\n",
       "      <td>2.450940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.757091</td>\n",
       "      <td>4.824440</td>\n",
       "      <td>4.828200</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>4.828200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.872780</td>\n",
       "      <td>5.707134</td>\n",
       "      <td>5.756821</td>\n",
       "      <td>-0.049688</td>\n",
       "      <td>5.756821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y   y_tilde  y - y_tilde  scikit y_tilde\n",
       "0   0.823319  4.823722  5.343674    -0.519952        5.343674\n",
       "1   0.192135  2.223278  2.186826     0.036452        2.186826\n",
       "2   0.793147  5.505977  5.103481     0.402496        5.103481\n",
       "3   0.476461  2.876920  3.123272    -0.246353        3.123272\n",
       "4   0.930851  5.922537  6.272629    -0.350091        6.272629\n",
       "..       ...       ...       ...          ...             ...\n",
       "95  0.495714  3.293497  3.215464     0.078033        3.215464\n",
       "96  0.943111  6.507975  6.385770     0.122205        6.385770\n",
       "97  0.300870  2.572539  2.450940     0.121598        2.450940\n",
       "98  0.757091  4.824440  4.828200    -0.003761        4.828200\n",
       "99  0.872780  5.707134  5.756821    -0.049688        5.756821\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_frame[\"scikit y_tilde\"] = ytilde_skl\n",
    "display(results_frame)\n",
    "# similar y_tilde result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b18c14",
   "metadata": {},
   "source": [
    "\n",
    "3. Using scikit-learn, compute also the mean square error, a risk metric corresponding to the expected value of the squared (quadratic) error defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cb698",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "MSE(\\boldsymbol{y},\\boldsymbol{\\tilde{y}}) = \\frac{1}{n}\n",
    "\\sum_{i=0}^{n-1}(y_i-\\tilde{y}_i)^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "aee2ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mse(y_true, y_pred):\n",
    "    n = len(y_true) # number of data points\n",
    "    mse = (1/n) * np.sum( (y_true - y_pred)**2 )\n",
    "    return mse \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "30e866d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated mean squared error: 0.05\n",
      "Scikit mean squared error:     0.05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calculated_mse = custom_mse(y, y_tilde)                          \n",
    "print(f\"Calculated mean squared error: {calculated_mse:.2f}\")\n",
    "\n",
    "# scikit mean squared error\n",
    "mse_skl = mean_squared_error(y, ytilde_skl)                          \n",
    "print(f\"Scikit mean squared error:     {mse_skl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be7228e",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the $R^2$ score function.\n",
    "If $\\tilde{\\boldsymbol{y}}_i$ is the predicted value of the $i-th$ sample and $y_i$ is the corresponding true value, then the score $R^2$ is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4f6de",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "R^2(\\boldsymbol{y}, \\tilde{\\boldsymbol{y}}) = 1 - \\frac{\\sum_{i=0}^{n - 1} (y_i - \\tilde{y}_i)^2}{\\sum_{i=0}^{n - 1} (y_i - \\bar{y})^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db66b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we have defined the mean value  of $\\boldsymbol{y}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9638fee",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\bar{y} =  \\frac{1}{n} \\sum_{i=0}^{n - 1} y_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "4f0a7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_r2(y_true, y_pred):\n",
    "    n = len(y_true) # number of data points\n",
    "    y_mean = (1/n) * np.sum(y_true)\n",
    "    r2 =  1 - ((np.sum( (y_true - y_pred)**2) ) / (np.sum( (y_true - y_mean)**2 )))\n",
    "    return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "a5cad10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated R^2: 0.98\n",
      "Scikit R^2:     0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calculated_r2 = custom_r2(y, y_tilde)                          \n",
    "print(f\"Calculated R^2: {calculated_r2:.2f}\")\n",
    "\n",
    "# scikit r^2 score\n",
    "mse_r2 = r2_score(y, ytilde_skl)                          \n",
    "print(f\"Scikit R^2:     {mse_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38df57",
   "metadata": {
    "editable": true
   },
   "source": [
    "You can use the functionality included in scikit-learn. If you feel for it, you can use your own program and define functions which compute the above two functions. \n",
    "Discuss the meaning of these results. Try also to vary the coefficient in front of the added stochastic noise term and discuss the quality of the fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "1ed79d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit predictions match manually created predictions\n",
    "# with low stochastic noise, the match is almost perfect.\n",
    "# fitting a second order polynomial with a second order polynomial should match well so that is as expected\n",
    "\n",
    "# increasing noise gradually makes the results diverge, it is no longer sufficient to match a simple polynomial\n",
    "# coefficient = 20 gives mse 358.28 and R^2 0.01 which is terrible\n",
    "# changing polynomial degree of model (P) does not help in either case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31937324",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 3: Split data in test and training data\n",
    "\n",
    "In this exercise we want you to to compute the MSE for the training\n",
    "data and the test data as function of the complexity of a polynomial,\n",
    "that is the degree of a given polynomial.\n",
    "\n",
    "The aim is to reproduce Figure 2.11 of [Hastie et al](https://github.com/CompPhysics/MLErasmus/blob/master/doc/Textbooks/elementsstat.pdf).\n",
    "\n",
    "Our data is defined by $x\\in [-3,3]$ with a total of for example $n=100$ data points. You should try to vary the number of data points $n$ in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "42a92590",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x input data, x train, x test\n",
      "(141, 1)\n",
      "(112, 1)\n",
      "(29, 1)\n",
      "y data, y train, y test\n",
      "(141, 1)\n",
      "(112, 1)\n",
      "(29, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_test</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.542857</td>\n",
       "      <td>0.114331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.685714</td>\n",
       "      <td>0.712772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.107522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.371429</td>\n",
       "      <td>1.160932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.828471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.120232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.291765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.671429</td>\n",
       "      <td>1.408068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.614286</td>\n",
       "      <td>0.127528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.057143</td>\n",
       "      <td>1.592712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-0.022582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.842857</td>\n",
       "      <td>-0.208153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.759134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.785714</td>\n",
       "      <td>-0.105201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.971456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.939694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.942857</td>\n",
       "      <td>0.477760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.828571</td>\n",
       "      <td>0.521796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.085714</td>\n",
       "      <td>0.866861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.442857</td>\n",
       "      <td>1.335308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.045703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.928571</td>\n",
       "      <td>0.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.928571</td>\n",
       "      <td>1.645685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.171429</td>\n",
       "      <td>0.915471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.528571</td>\n",
       "      <td>1.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.128571</td>\n",
       "      <td>0.929910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.728571</td>\n",
       "      <td>0.565986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.457143</td>\n",
       "      <td>-0.075369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_test    y_test\n",
       "0  -1.542857  0.114331\n",
       "1  -0.685714  0.712772\n",
       "2   0.000000  1.107522\n",
       "3   1.371429  1.160932\n",
       "4   0.685714  0.828471\n",
       "5   0.600000  1.120232\n",
       "6   1.500000  1.291765\n",
       "7   1.671429  1.408068\n",
       "8  -2.614286  0.127528\n",
       "9   2.057143  1.592712\n",
       "10 -1.800000 -0.022582\n",
       "11 -1.842857 -0.208153\n",
       "12  0.942857  0.759134\n",
       "13 -2.785714 -0.105201\n",
       "14  0.471429  0.971456\n",
       "15  0.214286  0.939694\n",
       "16 -0.942857  0.477760\n",
       "17  2.828571  0.521796\n",
       "18 -0.085714  0.866861\n",
       "19  2.442857  1.335308\n",
       "20  0.300000  1.045703\n",
       "21 -1.928571  0.046300\n",
       "22  1.928571  1.645685\n",
       "23 -0.171429  0.915471\n",
       "24  0.771429  0.640600\n",
       "25  2.528571  1.056900\n",
       "26 -0.128571  0.929910\n",
       "27 -0.728571  0.565986\n",
       "28 -1.457143 -0.075369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed()\n",
    "n = 100 + np.random.randint(0, 100) # vary data points by random extra\n",
    "# make data set\n",
    "x = np.linspace(-3, 3, n).reshape(-1, 1)\n",
    "y = np.exp(-x**2) + 1.5 * np.exp(-(x-2)**2)+ np.random.normal(0, 0.1, x.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(\"x input data, x train, x test\")\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(\"y data, y train, y test\")\n",
    "print(y.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# fancier display than numpy print\n",
    "results_frame_train = pd.DataFrame({\"x_train\":x_train.flatten(), \"y_train\":y_train.flatten()})\n",
    "results_frame_test = pd.DataFrame({\"x_test\":x_test.flatten(), \"y_test\":y_test.flatten()})\n",
    "display(results_frame_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1d96c",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $y$ is the function we want to fit with a given polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a15fc8",
   "metadata": {
    "editable": true
   },
   "source": [
    "**a)**\n",
    "Write a first code which sets up a design matrix $X$ defined by a fifth-order polynomial and split your data set in training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "f0f4d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix for training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.014286</td>\n",
       "      <td>4.057347</td>\n",
       "      <td>-8.172656</td>\n",
       "      <td>16.462064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>6.612245</td>\n",
       "      <td>17.002915</td>\n",
       "      <td>43.721783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.371429</td>\n",
       "      <td>1.880816</td>\n",
       "      <td>-2.579405</td>\n",
       "      <td>3.537470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.885714</td>\n",
       "      <td>3.555918</td>\n",
       "      <td>6.705446</td>\n",
       "      <td>12.644555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.530816</td>\n",
       "      <td>0.386738</td>\n",
       "      <td>0.281766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.700000</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>-19.683000</td>\n",
       "      <td>53.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.657143</td>\n",
       "      <td>7.060408</td>\n",
       "      <td>-18.760513</td>\n",
       "      <td>49.849363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.757143</td>\n",
       "      <td>3.087551</td>\n",
       "      <td>-5.425268</td>\n",
       "      <td>9.532971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.871429</td>\n",
       "      <td>8.245102</td>\n",
       "      <td>-23.675222</td>\n",
       "      <td>67.981708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>4.591837</td>\n",
       "      <td>9.839650</td>\n",
       "      <td>21.084965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2          3          4\n",
       "0    1.0 -2.014286  4.057347  -8.172656  16.462064\n",
       "1    1.0  2.571429  6.612245  17.002915  43.721783\n",
       "2    1.0 -1.371429  1.880816  -2.579405   3.537470\n",
       "3    1.0  1.885714  3.555918   6.705446  12.644555\n",
       "4    1.0  0.728571  0.530816   0.386738   0.281766\n",
       "..   ...       ...       ...        ...        ...\n",
       "107  1.0 -2.700000  7.290000 -19.683000  53.144100\n",
       "108  1.0 -2.657143  7.060408 -18.760513  49.849363\n",
       "109  1.0 -1.757143  3.087551  -5.425268   9.532971\n",
       "110  1.0 -2.871429  8.245102 -23.675222  67.981708\n",
       "111  1.0  2.142857  4.591837   9.839650  21.084965\n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix for test data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.542857</td>\n",
       "      <td>2.380408</td>\n",
       "      <td>-3.672630</td>\n",
       "      <td>5.666343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.685714</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>-0.322426</td>\n",
       "      <td>0.221092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.371429</td>\n",
       "      <td>1.880816</td>\n",
       "      <td>2.579405</td>\n",
       "      <td>3.537470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.221092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>5.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.671429</td>\n",
       "      <td>2.793673</td>\n",
       "      <td>4.669426</td>\n",
       "      <td>7.804611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.614286</td>\n",
       "      <td>6.834490</td>\n",
       "      <td>-17.867309</td>\n",
       "      <td>46.710251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.057143</td>\n",
       "      <td>4.231837</td>\n",
       "      <td>8.705493</td>\n",
       "      <td>17.908442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>3.240000</td>\n",
       "      <td>-5.832000</td>\n",
       "      <td>10.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.842857</td>\n",
       "      <td>3.396122</td>\n",
       "      <td>-6.258569</td>\n",
       "      <td>11.533648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.888980</td>\n",
       "      <td>0.838181</td>\n",
       "      <td>0.790285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.785714</td>\n",
       "      <td>7.760204</td>\n",
       "      <td>-21.617711</td>\n",
       "      <td>60.220767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.222245</td>\n",
       "      <td>0.104773</td>\n",
       "      <td>0.049393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.045918</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.002108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.942857</td>\n",
       "      <td>0.888980</td>\n",
       "      <td>-0.838181</td>\n",
       "      <td>0.790285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.828571</td>\n",
       "      <td>8.000816</td>\n",
       "      <td>22.630880</td>\n",
       "      <td>64.013062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.085714</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.442857</td>\n",
       "      <td>5.967551</td>\n",
       "      <td>14.577875</td>\n",
       "      <td>35.611665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.928571</td>\n",
       "      <td>3.719388</td>\n",
       "      <td>-7.173105</td>\n",
       "      <td>13.833845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>3.719388</td>\n",
       "      <td>7.173105</td>\n",
       "      <td>13.833845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.171429</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>-0.005038</td>\n",
       "      <td>0.000864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.595102</td>\n",
       "      <td>0.459079</td>\n",
       "      <td>0.354146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.528571</td>\n",
       "      <td>6.393673</td>\n",
       "      <td>16.166860</td>\n",
       "      <td>40.879060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.128571</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.728571</td>\n",
       "      <td>0.530816</td>\n",
       "      <td>-0.386738</td>\n",
       "      <td>0.281766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.457143</td>\n",
       "      <td>2.123265</td>\n",
       "      <td>-3.093901</td>\n",
       "      <td>4.508256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2          3          4\n",
       "0   1.0 -1.542857  2.380408  -3.672630   5.666343\n",
       "1   1.0 -0.685714  0.470204  -0.322426   0.221092\n",
       "2   1.0  0.000000  0.000000   0.000000   0.000000\n",
       "3   1.0  1.371429  1.880816   2.579405   3.537470\n",
       "4   1.0  0.685714  0.470204   0.322426   0.221092\n",
       "5   1.0  0.600000  0.360000   0.216000   0.129600\n",
       "6   1.0  1.500000  2.250000   3.375000   5.062500\n",
       "7   1.0  1.671429  2.793673   4.669426   7.804611\n",
       "8   1.0 -2.614286  6.834490 -17.867309  46.710251\n",
       "9   1.0  2.057143  4.231837   8.705493  17.908442\n",
       "10  1.0 -1.800000  3.240000  -5.832000  10.497600\n",
       "11  1.0 -1.842857  3.396122  -6.258569  11.533648\n",
       "12  1.0  0.942857  0.888980   0.838181   0.790285\n",
       "13  1.0 -2.785714  7.760204 -21.617711  60.220767\n",
       "14  1.0  0.471429  0.222245   0.104773   0.049393\n",
       "15  1.0  0.214286  0.045918   0.009840   0.002108\n",
       "16  1.0 -0.942857  0.888980  -0.838181   0.790285\n",
       "17  1.0  2.828571  8.000816  22.630880  64.013062\n",
       "18  1.0 -0.085714  0.007347  -0.000630   0.000054\n",
       "19  1.0  2.442857  5.967551  14.577875  35.611665\n",
       "20  1.0  0.300000  0.090000   0.027000   0.008100\n",
       "21  1.0 -1.928571  3.719388  -7.173105  13.833845\n",
       "22  1.0  1.928571  3.719388   7.173105  13.833845\n",
       "23  1.0 -0.171429  0.029388  -0.005038   0.000864\n",
       "24  1.0  0.771429  0.595102   0.459079   0.354146\n",
       "25  1.0  2.528571  6.393673  16.166860  40.879060\n",
       "26  1.0 -0.128571  0.016531  -0.002125   0.000273\n",
       "27  1.0 -0.728571  0.530816  -0.386738   0.281766\n",
       "28  1.0 -1.457143  2.123265  -3.093901   4.508256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make design matrix\n",
    "P = 5\n",
    "\n",
    "X_train = np.zeros((len(x_train), P))\n",
    "X_test = np.zeros((len(x_test), P))\n",
    "for exponent in range(0,P):\n",
    "    X_train[:,exponent] = x_train[:,0]**exponent\n",
    "    X_test[:,exponent] = x_test[:,0]**exponent\n",
    "\n",
    "print(\"feature matrix for training data\")\n",
    "df = pd.DataFrame(X_train)\n",
    "display(df)\n",
    "\n",
    "print(\"feature matrix for test data\")\n",
    "df = pd.DataFrame(X_test)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f9cbc",
   "metadata": {
    "editable": true
   },
   "source": [
    "**b)**\n",
    "Write thereafter (using either **scikit-learn** or your matrix inversion code using for example **numpy**)\n",
    "and perform an ordinary least squares fitting and compute the mean squared error for the training data and the test data. These calculations should apply to a model given by a fifth-order polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "4acd4ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X^T X shape: (5, 5)\n",
      "\n",
      "beta\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.855720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.466827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.035719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.039071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.855720\n",
       "1  0.466827\n",
       "2 -0.035719\n",
       "3 -0.039071\n",
       "4 -0.002552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add modelled y to display frame along with absolute error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_train</th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_tilde</th>\n",
       "      <th>y_train - y_tilde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.014286</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.047768</td>\n",
       "      <td>-0.030191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.571429</td>\n",
       "      <td>1.122265</td>\n",
       "      <td>1.044031</td>\n",
       "      <td>0.078234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.371429</td>\n",
       "      <td>0.071776</td>\n",
       "      <td>0.240070</td>\n",
       "      <td>-0.168294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.885714</td>\n",
       "      <td>1.408254</td>\n",
       "      <td>1.314745</td>\n",
       "      <td>0.093509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>1.161047</td>\n",
       "      <td>-0.450902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>-2.700000</td>\n",
       "      <td>-0.049647</td>\n",
       "      <td>-0.031720</td>\n",
       "      <td>-0.017928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>-2.657143</td>\n",
       "      <td>-0.094354</td>\n",
       "      <td>-0.031145</td>\n",
       "      <td>-0.063209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>-1.757143</td>\n",
       "      <td>-0.012387</td>\n",
       "      <td>0.112792</td>\n",
       "      <td>-0.125179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-2.871429</td>\n",
       "      <td>-0.032090</td>\n",
       "      <td>-0.027755</td>\n",
       "      <td>-0.004335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2.142857</td>\n",
       "      <td>1.468296</td>\n",
       "      <td>1.253784</td>\n",
       "      <td>0.214511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_train   y_train   y_tilde  y_train - y_tilde\n",
       "0   -2.014286  0.017576  0.047768          -0.030191\n",
       "1    2.571429  1.122265  1.044031           0.078234\n",
       "2   -1.371429  0.071776  0.240070          -0.168294\n",
       "3    1.885714  1.408254  1.314745           0.093509\n",
       "4    0.728571  0.710145  1.161047          -0.450902\n",
       "..        ...       ...       ...                ...\n",
       "107 -2.700000 -0.049647 -0.031720          -0.017928\n",
       "108 -2.657143 -0.094354 -0.031145          -0.063209\n",
       "109 -1.757143 -0.012387  0.112792          -0.125179\n",
       "110 -2.871429 -0.032090 -0.027755          -0.004335\n",
       "111  2.142857  1.468296  1.253784           0.214511\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted y compared with test y and their error\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_predict</th>\n",
       "      <th>y_test - y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.542857</td>\n",
       "      <td>0.114331</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>-0.065147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.685714</td>\n",
       "      <td>0.712772</td>\n",
       "      <td>0.530849</td>\n",
       "      <td>0.181923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.107522</td>\n",
       "      <td>0.855720</td>\n",
       "      <td>0.251801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.371429</td>\n",
       "      <td>1.160932</td>\n",
       "      <td>1.318950</td>\n",
       "      <td>-0.158018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.828471</td>\n",
       "      <td>1.145873</td>\n",
       "      <td>-0.317403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.120232</td>\n",
       "      <td>1.114188</td>\n",
       "      <td>0.006044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.291765</td>\n",
       "      <td>1.330807</td>\n",
       "      <td>-0.039041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.671429</td>\n",
       "      <td>1.408068</td>\n",
       "      <td>1.333841</td>\n",
       "      <td>0.074228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.614286</td>\n",
       "      <td>0.127528</td>\n",
       "      <td>-0.029954</td>\n",
       "      <td>0.157482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.057143</td>\n",
       "      <td>1.592712</td>\n",
       "      <td>1.279050</td>\n",
       "      <td>0.313661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.800000</td>\n",
       "      <td>-0.022582</td>\n",
       "      <td>0.100769</td>\n",
       "      <td>-0.123352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.842857</td>\n",
       "      <td>-0.208153</td>\n",
       "      <td>0.089208</td>\n",
       "      <td>-0.297361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.759134</td>\n",
       "      <td>1.229352</td>\n",
       "      <td>-0.470219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.785714</td>\n",
       "      <td>-0.105201</td>\n",
       "      <td>-0.031001</td>\n",
       "      <td>-0.074201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.971456</td>\n",
       "      <td>1.063638</td>\n",
       "      <td>-0.092182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.939694</td>\n",
       "      <td>0.953725</td>\n",
       "      <td>-0.014031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.942857</td>\n",
       "      <td>0.477760</td>\n",
       "      <td>0.414547</td>\n",
       "      <td>0.063213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.828571</td>\n",
       "      <td>0.521796</td>\n",
       "      <td>0.842791</td>\n",
       "      <td>-0.320994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.085714</td>\n",
       "      <td>0.866861</td>\n",
       "      <td>0.815469</td>\n",
       "      <td>0.051393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.442857</td>\n",
       "      <td>1.335308</td>\n",
       "      <td>1.122487</td>\n",
       "      <td>0.212820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.045703</td>\n",
       "      <td>0.991478</td>\n",
       "      <td>0.054225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.928571</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>0.067508</td>\n",
       "      <td>-0.021208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.928571</td>\n",
       "      <td>1.645685</td>\n",
       "      <td>1.307606</td>\n",
       "      <td>0.338079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.171429</td>\n",
       "      <td>0.915471</td>\n",
       "      <td>0.774838</td>\n",
       "      <td>0.140633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.640600</td>\n",
       "      <td>1.175747</td>\n",
       "      <td>-0.535147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.528571</td>\n",
       "      <td>1.056900</td>\n",
       "      <td>1.071752</td>\n",
       "      <td>-0.014853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.128571</td>\n",
       "      <td>0.929910</td>\n",
       "      <td>0.795192</td>\n",
       "      <td>0.134719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.728571</td>\n",
       "      <td>0.565986</td>\n",
       "      <td>0.511035</td>\n",
       "      <td>0.054952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.457143</td>\n",
       "      <td>-0.075369</td>\n",
       "      <td>0.209021</td>\n",
       "      <td>-0.284389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x_test    y_test  y_predict  y_test - y_predict\n",
       "0  -1.542857  0.114331   0.179477           -0.065147\n",
       "1  -0.685714  0.712772   0.530849            0.181923\n",
       "2   0.000000  1.107522   0.855720            0.251801\n",
       "3   1.371429  1.160932   1.318950           -0.158018\n",
       "4   0.685714  0.828471   1.145873           -0.317403\n",
       "5   0.600000  1.120232   1.114188            0.006044\n",
       "6   1.500000  1.291765   1.330807           -0.039041\n",
       "7   1.671429  1.408068   1.333841            0.074228\n",
       "8  -2.614286  0.127528  -0.029954            0.157482\n",
       "9   2.057143  1.592712   1.279050            0.313661\n",
       "10 -1.800000 -0.022582   0.100769           -0.123352\n",
       "11 -1.842857 -0.208153   0.089208           -0.297361\n",
       "12  0.942857  0.759134   1.229352           -0.470219\n",
       "13 -2.785714 -0.105201  -0.031001           -0.074201\n",
       "14  0.471429  0.971456   1.063638           -0.092182\n",
       "15  0.214286  0.939694   0.953725           -0.014031\n",
       "16 -0.942857  0.477760   0.414547            0.063213\n",
       "17  2.828571  0.521796   0.842791           -0.320994\n",
       "18 -0.085714  0.866861   0.815469            0.051393\n",
       "19  2.442857  1.335308   1.122487            0.212820\n",
       "20  0.300000  1.045703   0.991478            0.054225\n",
       "21 -1.928571  0.046300   0.067508           -0.021208\n",
       "22  1.928571  1.645685   1.307606            0.338079\n",
       "23 -0.171429  0.915471   0.774838            0.140633\n",
       "24  0.771429  0.640600   1.175747           -0.535147\n",
       "25  2.528571  1.056900   1.071752           -0.014853\n",
       "26 -0.128571  0.929910   0.795192            0.134719\n",
       "27 -0.728571  0.565986   0.511035            0.054952\n",
       "28 -1.457143 -0.075369   0.209021           -0.284389"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated mean squared error: 0.05\n",
      "Calculated R^2: 0.82\n"
     ]
    }
   ],
   "source": [
    "# optimal beta is given by\n",
    "# beta_hat = (X^T X)^-1 X^T y\n",
    "\n",
    "x_t_x = np.matmul(X_train.T, X_train)\n",
    "print(\"X^T X shape:\", x_t_x.shape)\n",
    "calc_invert = np.linalg.inv(x_t_x)\n",
    "\n",
    "beta = calc_invert.dot(X_train.T).dot(y_train)\n",
    "df = pd.DataFrame(beta)\n",
    "print(\"\\nbeta\")\n",
    "display(df)\n",
    "\n",
    "y_tilde = X_train @ beta\n",
    "\n",
    "print(\"add modelled y to display frame along with absolute error\")\n",
    "results_frame_train[\"y_tilde\"] = y_tilde.flatten()\n",
    "results_frame_train[\"y_train - y_tilde\"] = y_train.flatten()-y_tilde.flatten()\n",
    "display(results_frame_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = X_test @ beta\n",
    "\n",
    "print(\"predicted y compared with test y and their error\")\n",
    "results_frame_test[\"y_predict\"] = y_pred.flatten()\n",
    "results_frame_test[\"y_test - y_predict\"] = y_test.flatten()-y_pred.flatten()\n",
    "display(results_frame_test)\n",
    "\n",
    "calculated_mse = custom_mse(y_test, y_pred)                          \n",
    "print(f\"Calculated mean squared error: {calculated_mse:.2f}\")\n",
    "\n",
    "calculated_r2 = custom_r2(y_test, y_pred)                          \n",
    "print(f\"Calculated R^2: {calculated_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41d9d9",
   "metadata": {
    "editable": true
   },
   "source": [
    "**c)**\n",
    "Add now a model which allows you to make polynomials up to degree $15$.  Perform a standard OLS fitting of the training data and compute the MSE for the training and test data and plot both test and training data MSE as functions of the polynomial degree. Compare what you see with Figure 2.11 of Hastie et al. Comment your results. For which polynomial degree do you find an optimal MSE (smallest value)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "29f4bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_matrix(x, P):\n",
    "    X = np.zeros((len(x), P))\n",
    "    for exponent in range(0,P):\n",
    "        X[:,exponent] = x[:,0]**exponent\n",
    "\n",
    "    return X\n",
    "\n",
    "def linear_regression_model(X, y):\n",
    "    beta = (np.linalg.inv(X.T.dot(X))).dot(X.T).dot(y)\n",
    "\n",
    "    return beta\n",
    "\n",
    "def linear_prediction(X, beta):\n",
    "    y_tilde = X @ beta\n",
    "\n",
    "    return y_tilde                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "16c632af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points: 777\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "np.random.seed()\n",
    "\n",
    "n = 100 + np.random.randint(0, 1000)\n",
    "print(f\"number of data points: {n}\")\n",
    "\n",
    "x_full = np.linspace(-3, 3, n).reshape(-1, 1)\n",
    "y_full = np.exp(-x_full**2) + 1.5 * np.exp(-(x_full-2)**2)+ np.random.normal(0, 0.1, x_full.shape)\n",
    "\n",
    "P = 16\n",
    "P = 27\n",
    "features_list = list(range(1, P))\n",
    "print(features_list)\n",
    "\n",
    "train_mses_list = []\n",
    "train_r2_list = []\n",
    "test_mses_list = []\n",
    "test_r2_list = []\n",
    "for features in features_list:\n",
    "    calc_feature_matrix = make_feature_matrix(x_full, features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(calc_feature_matrix, y_full, test_size=0.2)\n",
    "\n",
    "    calc_beta = linear_regression_model(X_train, y_train)\n",
    "    y_tilde = linear_prediction(X_train, calc_beta)\n",
    "    y_prediction = linear_prediction(X_test, calc_beta)\n",
    "\n",
    "    #results_frame_test = pd.DataFrame({\"x_test\":x_full[len(y_train):].flatten(), \"y_test\":y_test.flatten()})\n",
    "    #results_frame_test[\"y_prediction\"] = y_prediction.flatten()\n",
    "\n",
    "    #display(results_frame_test)\n",
    "\n",
    "    train_calculated_mse = custom_mse(y_train, y_tilde)\n",
    "    train_mses_list.append(train_calculated_mse)\n",
    "    train_calculated_r2 = custom_r2(y_train, y_tilde)\n",
    "    train_r2_list.append(train_calculated_r2)\n",
    "\n",
    "    #print(f\"Train data mean squared error: {train_calculated_mse:.3f}\")\n",
    "    #print(f\"Train data R^2: {train_calculated_r2:.3f}\")\n",
    "\n",
    "    #print()\n",
    "\n",
    "    test_calculated_mse = custom_mse(y_test, y_prediction)\n",
    "    test_mses_list.append(test_calculated_mse)\n",
    "    test_calculated_r2 = custom_r2(y_test, y_prediction)\n",
    "    test_r2_list.append(test_calculated_mse)\n",
    "\n",
    "    #print(f\"Test data mean squared error: {test_calculated_mse:.3f}\")\n",
    "    #print(f\"Test data R^2: {test_calculated_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "e799ce09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(r'Polynomial Degree')\n",
    "ax.set_ylabel(r'Mean Squared Error')\n",
    "ax.plot(features_list, train_mses_list, alpha=0.7, lw=2,\n",
    "            label='Training set')\n",
    "ax.plot(features_list, test_mses_list, alpha=0.7, lw=2, c='m',\n",
    "            label='Test set')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
