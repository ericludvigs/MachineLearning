<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 45,  Convolutional Neural Networks (CCNs) and Recurrent Neural Networks (RNNs)">
<title>Week 45,  Convolutional Neural Networks (CCNs) and Recurrent Neural Networks (RNNs)</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for week 45', 2, None, 'plans-for-week-45'),
              ('Material for the lab sessions, additional ways to present '
               'classification results and other practicalities',
               2,
               None,
               'material-for-the-lab-sessions-additional-ways-to-present-classification-results-and-other-practicalities'),
              ('Material for Lecture Monday November 4',
               2,
               None,
               'material-for-lecture-monday-november-4'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('What is the Difference', 2, None, 'what-is-the-difference'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs donâ€™t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('A deep CNN model ("From Raschka et '
               'al":"https://github.com/rasbt/machine-learning-book")',
               2,
               None,
               'a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book'),
              ('Key Idea', 2, None, 'key-idea'),
              ('Building convolutional neural networks in Tensorflow and Keras',
               2,
               None,
               'building-convolutional-neural-networks-in-tensorflow-and-keras'),
              ('Setting it up', 2, None, 'setting-it-up'),
              ('The MNIST dataset again', 2, None, 'the-mnist-dataset-again'),
              ('Strong correlations', 2, None, 'strong-correlations'),
              ('Layers of a CNN', 2, None, 'layers-of-a-cnn'),
              ('Systematic reduction', 2, None, 'systematic-reduction'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               'prerequisites-collect-and-pre-process-data'),
              ('Importing Keras and Tensorflow',
               2,
               None,
               'importing-keras-and-tensorflow'),
              ('Running with Keras', 2, None, 'running-with-keras'),
              ('Final part', 2, None, 'final-part'),
              ('Final visualization', 2, None, 'final-visualization'),
              ('The CIFAR01 data set', 2, None, 'the-cifar01-data-set'),
              ('Verifying the data set', 2, None, 'verifying-the-data-set'),
              ('Set up  the model', 2, None, 'set-up-the-model'),
              ('Add Dense layers on top', 2, None, 'add-dense-layers-on-top'),
              ('Compile and train the model',
               2,
               None,
               'compile-and-train-the-model'),
              ('Finally, evaluate the model',
               2,
               None,
               'finally-evaluate-the-model'),
              ('Building our own CNN code',
               2,
               None,
               'building-our-own-cnn-code'),
              ('List of contents:', 3, None, 'list-of-contents'),
              ('Schedulers', 3, None, 'schedulers'),
              ('Usage of schedulers', 3, None, 'usage-of-schedulers'),
              ('Cost functions', 3, None, 'cost-functions'),
              ('Usage of cost functions', 3, None, 'usage-of-cost-functions'),
              ('Activation functions', 3, None, 'activation-functions'),
              ('Usage of activation functions',
               3,
               None,
               'usage-of-activation-functions'),
              ('Convolution', 3, None, 'convolution'),
              ('Layers', 3, None, 'layers'),
              ('Convolution2DLayer: convolution in a hidden layer',
               3,
               None,
               'convolution2dlayer-convolution-in-a-hidden-layer'),
              ('Backpropagation in the convolutional layer',
               3,
               None,
               'backpropagation-in-the-convolutional-layer'),
              ('Demonstration', 3, None, 'demonstration'),
              ('Pooling Layer', 3, None, 'pooling-layer'),
              ('Flattening Layer', 3, None, 'flattening-layer'),
              ('Fully Connected Layers', 3, None, 'fully-connected-layers'),
              ('Optimized Convolution2DLayer',
               3,
               None,
               'optimized-convolution2dlayer'),
              ('The Convolutional Neural Network (CNN)',
               3,
               None,
               'the-convolutional-neural-network-cnn'),
              ('Usage of CNN code', 3, None, 'usage-of-cnn-code'),
              ('Additional Remarks', 3, None, 'additional-remarks'),
              ('Remarks on the speed', 3, None, 'remarks-on-the-speed'),
              ('Convolution using separable kernels',
               3,
               None,
               'convolution-using-separable-kernels'),
              ('Convolution in the Fourier domain',
               3,
               None,
               'convolution-in-the-fourier-domain'),
              ('From FFNNs and CNNs to recurrent neural networks (RNNs)',
               2,
               None,
               'from-ffnns-and-cnns-to-recurrent-neural-networks-rnns'),
              ('Feedback connections', 2, None, 'feedback-connections'),
              ('Vanishing gradients', 2, None, 'vanishing-gradients'),
              ('Recurrent neural networks (RNNs): Overarching view',
               2,
               None,
               'recurrent-neural-networks-rnns-overarching-view'),
              ('Sequential data only?', 2, None, 'sequential-data-only'),
              ('Differential equations', 2, None, 'differential-equations'),
              ('A simple example', 2, None, 'a-simple-example'),
              ('RNNs', 2, None, 'rnns'),
              ('What kinds of behaviour can RNNs exhibit?',
               2,
               None,
               'what-kinds-of-behaviour-can-rnns-exhibit'),
              ('Basic layout,  "Figures from Sebastian Rashcka et al, Machine '
               'learning with Sickit-Learn and '
               'PyTorch":"https://sebastianraschka.com/blog/2022/ml-pytorch-book.html"',
               2,
               None,
               'basic-layout-figures-from-sebastian-rashcka-et-al-machine-learning-with-sickit-learn-and-pytorch-https-sebastianraschka-com-blog-2022-ml-pytorch-book-html'),
              ('Solving differential equations with RNNs',
               2,
               None,
               'solving-differential-equations-with-rnns'),
              ('Two first-order differential equations',
               2,
               None,
               'two-first-order-differential-equations'),
              ('Velocity only', 2, None, 'velocity-only'),
              ('Linking with RNNs', 2, None, 'linking-with-rnns'),
              ('Minor rewrite', 2, None, 'minor-rewrite'),
              ('RNNs in more detail', 2, None, 'rnns-in-more-detail'),
              ('RNNs in more detail, part 2',
               2,
               None,
               'rnns-in-more-detail-part-2'),
              ('RNNs in more detail, part 3',
               2,
               None,
               'rnns-in-more-detail-part-3'),
              ('RNNs in more detail, part 4',
               2,
               None,
               'rnns-in-more-detail-part-4'),
              ('RNNs in more detail, part 5',
               2,
               None,
               'rnns-in-more-detail-part-5'),
              ('RNNs in more detail, part 6',
               2,
               None,
               'rnns-in-more-detail-part-6'),
              ('RNNs in more detail, part 7',
               2,
               None,
               'rnns-in-more-detail-part-7'),
              ('Backpropagation through time',
               2,
               None,
               'backpropagation-through-time'),
              ('The backward pass is linear',
               2,
               None,
               'the-backward-pass-is-linear'),
              ('The problem of exploding or vanishing gradients',
               2,
               None,
               'the-problem-of-exploding-or-vanishing-gradients'),
              ('Mathematical setup', 2, None, 'mathematical-setup'),
              ('Back propagation in time through figures, part 1',
               2,
               None,
               'back-propagation-in-time-through-figures-part-1'),
              ('Back propagation in time, part 2',
               2,
               None,
               'back-propagation-in-time-part-2'),
              ('Back propagation in time, part 3',
               2,
               None,
               'back-propagation-in-time-part-3'),
              ('Back propagation in time, part 4',
               2,
               None,
               'back-propagation-in-time-part-4'),
              ('Back propagation in time in equations',
               2,
               None,
               'back-propagation-in-time-in-equations'),
              ('Chain rule again', 2, None, 'chain-rule-again'),
              ('Gradients of loss functions',
               2,
               None,
               'gradients-of-loss-functions'),
              ('Summary of RNNs', 2, None, 'summary-of-rnns'),
              ('Summary of a  typical RNN',
               2,
               None,
               'summary-of-a-typical-rnn'),
              ('Four effective ways to learn an RNN and preparing for next '
               'week',
               2,
               None,
               'four-effective-ways-to-learn-an-rnn-and-preparing-for-next-week'),
              ('Gating mechanism: Long Short Term Memory (LSTM)',
               2,
               None,
               'gating-mechanism-long-short-term-memory-lstm'),
              ('Implementing a memory cell in a neural network',
               2,
               None,
               'implementing-a-memory-cell-in-a-neural-network'),
              ('LSTM details', 2, None, 'lstm-details'),
              ('Basic layout', 2, None, 'basic-layout'),
              ('More LSTM details', 2, None, 'more-lstm-details'),
              ('The forget gate', 2, None, 'the-forget-gate'),
              ('Input gate', 2, None, 'input-gate'),
              ('Forget and input', 2, None, 'forget-and-input'),
              ('Output gate', 2, None, 'output-gate')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week45-bs.html">Week 45,  Convolutional Neural Networks (CCNs) and Recurrent Neural Networks (RNNs)</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week45-bs001.html#plans-for-week-45" style="font-size: 80%;"><b>Plans for week 45</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs002.html#material-for-the-lab-sessions-additional-ways-to-present-classification-results-and-other-practicalities" style="font-size: 80%;"><b>Material for the lab sessions, additional ways to present classification results and other practicalities</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs003.html#material-for-lecture-monday-november-4" style="font-size: 80%;"><b>Material for Lecture Monday November 4</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs004.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;"><b>Convolutional Neural Networks (recognizing images)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs005.html#what-is-the-difference" style="font-size: 80%;"><b>What is the Difference</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs006.html#neural-networks-vs-cnns" style="font-size: 80%;"><b>Neural Networks vs CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs007.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;"><b>Why CNNS for images, sound files, medical images from CT scans etc?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs008.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;"><b>Regular NNs donâ€™t scale well to full images</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs009.html#3d-volumes-of-neurons" style="font-size: 80%;"><b>3D volumes of neurons</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs010.html#layers-used-to-build-cnns" style="font-size: 80%;"><b>Layers used to build CNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs011.html#cnns-in-brief" style="font-size: 80%;"><b>CNNs in brief</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs012.html#a-deep-cnn-model-from-raschka-et-al-https-github-com-rasbt-machine-learning-book" style="font-size: 80%;"><b>A deep CNN model ("From Raschka et al":"https://github.com/rasbt/machine-learning-book")</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs013.html#key-idea" style="font-size: 80%;"><b>Key Idea</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs014.html#building-convolutional-neural-networks-in-tensorflow-and-keras" style="font-size: 80%;"><b>Building convolutional neural networks in Tensorflow and Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs015.html#setting-it-up" style="font-size: 80%;"><b>Setting it up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs016.html#the-mnist-dataset-again" style="font-size: 80%;"><b>The MNIST dataset again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs017.html#strong-correlations" style="font-size: 80%;"><b>Strong correlations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs018.html#layers-of-a-cnn" style="font-size: 80%;"><b>Layers of a CNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs019.html#systematic-reduction" style="font-size: 80%;"><b>Systematic reduction</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#prerequisites-collect-and-pre-process-data" style="font-size: 80%;"><b>Prerequisites: Collect and pre-process data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs021.html#importing-keras-and-tensorflow" style="font-size: 80%;"><b>Importing Keras and Tensorflow</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#running-with-keras" style="font-size: 80%;"><b>Running with Keras</b></a></li>
     <!-- navigation toc: --> <li><a href="#final-part" style="font-size: 80%;"><b>Final part</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs024.html#final-visualization" style="font-size: 80%;"><b>Final visualization</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs025.html#the-cifar01-data-set" style="font-size: 80%;"><b>The CIFAR01 data set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs026.html#verifying-the-data-set" style="font-size: 80%;"><b>Verifying the data set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs027.html#set-up-the-model" style="font-size: 80%;"><b>Set up  the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs028.html#add-dense-layers-on-top" style="font-size: 80%;"><b>Add Dense layers on top</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs029.html#compile-and-train-the-model" style="font-size: 80%;"><b>Compile and train the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs030.html#finally-evaluate-the-model" style="font-size: 80%;"><b>Finally, evaluate the model</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#building-our-own-cnn-code" style="font-size: 80%;"><b>Building our own CNN code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#list-of-contents" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;List of contents:</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#usage-of-schedulers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of schedulers</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#usage-of-cost-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of cost functions</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#usage-of-activation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of activation functions</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#convolution" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#convolution2dlayer-convolution-in-a-hidden-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution2DLayer: convolution in a hidden layer</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#backpropagation-in-the-convolutional-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Backpropagation in the convolutional layer</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#demonstration" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Demonstration</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#pooling-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Pooling Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#flattening-layer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Flattening Layer</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#fully-connected-layers" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Fully Connected Layers</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#optimized-convolution2dlayer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimized Convolution2DLayer</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#the-convolutional-neural-network-cnn" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The Convolutional Neural Network (CNN)</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#usage-of-cnn-code" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Usage of CNN code</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#additional-remarks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Additional Remarks</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#remarks-on-the-speed" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Remarks on the speed</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#convolution-using-separable-kernels" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution using separable kernels</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#convolution-in-the-fourier-domain" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Convolution in the Fourier domain</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs032.html#from-ffnns-and-cnns-to-recurrent-neural-networks-rnns" style="font-size: 80%;"><b>From FFNNs and CNNs to recurrent neural networks (RNNs)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs033.html#feedback-connections" style="font-size: 80%;"><b>Feedback connections</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs034.html#vanishing-gradients" style="font-size: 80%;"><b>Vanishing gradients</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs035.html#recurrent-neural-networks-rnns-overarching-view" style="font-size: 80%;"><b>Recurrent neural networks (RNNs): Overarching view</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs036.html#sequential-data-only" style="font-size: 80%;"><b>Sequential data only?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs037.html#differential-equations" style="font-size: 80%;"><b>Differential equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs038.html#a-simple-example" style="font-size: 80%;"><b>A simple example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs039.html#rnns" style="font-size: 80%;"><b>RNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs040.html#what-kinds-of-behaviour-can-rnns-exhibit" style="font-size: 80%;"><b>What kinds of behaviour can RNNs exhibit?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs041.html#basic-layout-figures-from-sebastian-rashcka-et-al-machine-learning-with-sickit-learn-and-pytorch-https-sebastianraschka-com-blog-2022-ml-pytorch-book-html" style="font-size: 80%;"><b>Basic layout,  "Figures from Sebastian Rashcka et al, Machine learning with Sickit-Learn and PyTorch":"https://sebastianraschka.com/blog/2022/ml-pytorch-book.html"</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs042.html#solving-differential-equations-with-rnns" style="font-size: 80%;"><b>Solving differential equations with RNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs043.html#two-first-order-differential-equations" style="font-size: 80%;"><b>Two first-order differential equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs044.html#velocity-only" style="font-size: 80%;"><b>Velocity only</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs045.html#linking-with-rnns" style="font-size: 80%;"><b>Linking with RNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs046.html#minor-rewrite" style="font-size: 80%;"><b>Minor rewrite</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs047.html#rnns-in-more-detail" style="font-size: 80%;"><b>RNNs in more detail</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs048.html#rnns-in-more-detail-part-2" style="font-size: 80%;"><b>RNNs in more detail, part 2</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs049.html#rnns-in-more-detail-part-3" style="font-size: 80%;"><b>RNNs in more detail, part 3</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs050.html#rnns-in-more-detail-part-4" style="font-size: 80%;"><b>RNNs in more detail, part 4</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs051.html#rnns-in-more-detail-part-5" style="font-size: 80%;"><b>RNNs in more detail, part 5</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs052.html#rnns-in-more-detail-part-6" style="font-size: 80%;"><b>RNNs in more detail, part 6</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs053.html#rnns-in-more-detail-part-7" style="font-size: 80%;"><b>RNNs in more detail, part 7</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs054.html#backpropagation-through-time" style="font-size: 80%;"><b>Backpropagation through time</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs055.html#the-backward-pass-is-linear" style="font-size: 80%;"><b>The backward pass is linear</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs056.html#the-problem-of-exploding-or-vanishing-gradients" style="font-size: 80%;"><b>The problem of exploding or vanishing gradients</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs057.html#mathematical-setup" style="font-size: 80%;"><b>Mathematical setup</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs058.html#back-propagation-in-time-through-figures-part-1" style="font-size: 80%;"><b>Back propagation in time through figures, part 1</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs059.html#back-propagation-in-time-part-2" style="font-size: 80%;"><b>Back propagation in time, part 2</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs060.html#back-propagation-in-time-part-3" style="font-size: 80%;"><b>Back propagation in time, part 3</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs061.html#back-propagation-in-time-part-4" style="font-size: 80%;"><b>Back propagation in time, part 4</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs062.html#back-propagation-in-time-in-equations" style="font-size: 80%;"><b>Back propagation in time in equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs063.html#chain-rule-again" style="font-size: 80%;"><b>Chain rule again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs064.html#gradients-of-loss-functions" style="font-size: 80%;"><b>Gradients of loss functions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs065.html#summary-of-rnns" style="font-size: 80%;"><b>Summary of RNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs066.html#summary-of-a-typical-rnn" style="font-size: 80%;"><b>Summary of a  typical RNN</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs067.html#four-effective-ways-to-learn-an-rnn-and-preparing-for-next-week" style="font-size: 80%;"><b>Four effective ways to learn an RNN and preparing for next week</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs068.html#gating-mechanism-long-short-term-memory-lstm" style="font-size: 80%;"><b>Gating mechanism: Long Short Term Memory (LSTM)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs069.html#implementing-a-memory-cell-in-a-neural-network" style="font-size: 80%;"><b>Implementing a memory cell in a neural network</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs070.html#lstm-details" style="font-size: 80%;"><b>LSTM details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs071.html#basic-layout" style="font-size: 80%;"><b>Basic layout</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs072.html#more-lstm-details" style="font-size: 80%;"><b>More LSTM details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs073.html#the-forget-gate" style="font-size: 80%;"><b>The forget gate</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs074.html#input-gate" style="font-size: 80%;"><b>Input gate</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs075.html#forget-and-input" style="font-size: 80%;"><b>Forget and input</b></a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs076.html#output-gate" style="font-size: 80%;"><b>Output gate</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0023"></a>
<!-- !split -->
<h2 id="final-part" class="anchor">Final part </h2>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">CNN_keras <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(eta_vals), <span style="color: #008000">len</span>(lmbd_vals)), dtype<span style="color: #666666">=</span><span style="color: #008000">object</span>)
        
<span style="color: #008000; font-weight: bold">for</span> i, eta <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(eta_vals):
    <span style="color: #008000; font-weight: bold">for</span> j, lmbd <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(lmbd_vals):
        CNN <span style="color: #666666">=</span> create_convolutional_neural_network_keras(input_shape, receptive_field,
                                              n_filters, n_neurons_connected, n_categories,
                                              eta, lmbd)
        CNN<span style="color: #666666">.</span>fit(X_train, Y_train, epochs<span style="color: #666666">=</span>epochs, batch_size<span style="color: #666666">=</span>batch_size, verbose<span style="color: #666666">=0</span>)
        scores <span style="color: #666666">=</span> CNN<span style="color: #666666">.</span>evaluate(X_test, Y_test)
        
        CNN_keras[i][j] <span style="color: #666666">=</span> CNN
        
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Learning rate = &quot;</span>, eta)
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Lambda = &quot;</span>, lmbd)
        <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Test accuracy: </span><span style="color: #BB6688; font-weight: bold">%.3f</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">%</span> scores[<span style="color: #666666">1</span>])
        <span style="color: #008000">print</span>()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week45-bs022.html">&laquo;</a></li>
  <li><a href="._week45-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week45-bs015.html">16</a></li>
  <li><a href="._week45-bs016.html">17</a></li>
  <li><a href="._week45-bs017.html">18</a></li>
  <li><a href="._week45-bs018.html">19</a></li>
  <li><a href="._week45-bs019.html">20</a></li>
  <li><a href="._week45-bs020.html">21</a></li>
  <li><a href="._week45-bs021.html">22</a></li>
  <li><a href="._week45-bs022.html">23</a></li>
  <li class="active"><a href="._week45-bs023.html">24</a></li>
  <li><a href="._week45-bs024.html">25</a></li>
  <li><a href="._week45-bs025.html">26</a></li>
  <li><a href="._week45-bs026.html">27</a></li>
  <li><a href="._week45-bs027.html">28</a></li>
  <li><a href="._week45-bs028.html">29</a></li>
  <li><a href="._week45-bs029.html">30</a></li>
  <li><a href="._week45-bs030.html">31</a></li>
  <li><a href="._week45-bs031.html">32</a></li>
  <li><a href="._week45-bs032.html">33</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week45-bs076.html">77</a></li>
  <li><a href="._week45-bs024.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

