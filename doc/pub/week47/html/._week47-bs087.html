<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week47.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week47-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 47: Unsupervised learning (PCA and Clustering)  and Summary of Course">
<title>Week 47: Unsupervised learning (PCA and Clustering)  and Summary of Course</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week47.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week47-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of week 47', 2, None, 'overview-of-week-47'),
              ('Basic ideas of the Principal Component Analysis (PCA)',
               2,
               None,
               'basic-ideas-of-the-principal-component-analysis-pca'),
              ('Introducing the Covariance and Correlation functions',
               2,
               None,
               'introducing-the-covariance-and-correlation-functions'),
              ('More on the covariance', 2, None, 'more-on-the-covariance'),
              ('Reminding ourselves about Linear Regression',
               2,
               None,
               'reminding-ourselves-about-linear-regression'),
              ('Simple Example', 2, None, 'simple-example'),
              ('The Correlation Matrix', 2, None, 'the-correlation-matrix'),
              ('Numpy Functionality', 2, None, 'numpy-functionality'),
              ('Correlation Matrix again', 2, None, 'correlation-matrix-again'),
              ('Using Pandas', 2, None, 'using-pandas'),
              ('And then the Franke Function',
               2,
               None,
               'and-then-the-franke-function'),
              ('Links with the Design Matrix',
               2,
               None,
               'links-with-the-design-matrix'),
              ('Computing the Expectation Values',
               2,
               None,
               'computing-the-expectation-values'),
              ('Towards the PCA theorem', 2, None, 'towards-the-pca-theorem'),
              ('More on the PCA Theorem', 2, None, 'more-on-the-pca-theorem'),
              ("A kind of Bird's view  on PCA",
               2,
               None,
               'a-kind-of-bird-s-view-on-pca'),
              ('Writing our own PCA code', 2, None, 'writing-our-own-pca-code'),
              ('Implementing it', 2, None, 'implementing-it'),
              ('First Step', 2, None, 'first-step'),
              ('Scaling', 2, None, 'scaling'),
              ('Centered Data', 2, None, 'centered-data'),
              ('Exploring', 2, None, 'exploring'),
              ('Diagonalize the sample covariance matrix to obtain the '
               'principal components',
               2,
               None,
               'diagonalize-the-sample-covariance-matrix-to-obtain-the-principal-components'),
              ('Collecting all Steps', 2, None, 'collecting-all-steps'),
              ('Classical PCA Theorem', 2, None, 'classical-pca-theorem'),
              ('The PCA Theorem', 2, None, 'the-pca-theorem'),
              ('Geometric Interpretation and link with Singular Value '
               'Decomposition',
               2,
               None,
               'geometric-interpretation-and-link-with-singular-value-decomposition'),
              ('PCA and scikit-learn', 2, None, 'pca-and-scikit-learn'),
              ('Back to the Cancer Data', 2, None, 'back-to-the-cancer-data'),
              ('Incremental PCA', 2, None, 'incremental-pca'),
              ('Randomized PCA', 3, None, 'randomized-pca'),
              ('Kernel PCA', 3, None, 'kernel-pca'),
              ('Other techniques', 2, None, 'other-techniques'),
              ('Clustering and Unsupervised Learning',
               2,
               None,
               'clustering-and-unsupervised-learning'),
              ('Basic Idea of the $k$-means Clustering Algorithm',
               2,
               None,
               'basic-idea-of-the-k-means-clustering-algorithm'),
              ('The $k$-means Algorithm', 2, None, 'the-k-means-algorithm'),
              ('Basic Math of the $k$-means Algorithm',
               2,
               None,
               'basic-math-of-the-k-means-algorithm'),
              ('Within Cluster Point Scatter',
               2,
               None,
               'within-cluster-point-scatter'),
              ('More Details', 2, None, 'more-details'),
              ('Total Cluster Variance', 2, None, 'total-cluster-variance'),
              ('The $k$-means Clustering Algorithm',
               2,
               None,
               'the-k-means-clustering-algorithm'),
              ('Summarizing', 2, None, 'summarizing'),
              ('Writing our own Code, the Data Set',
               2,
               None,
               'writing-our-own-code-the-data-set'),
              ('Implementing the $k$-means Algorithm',
               2,
               None,
               'implementing-the-k-means-algorithm'),
              ('Plotting', 2, None, 'plotting'),
              ('Continuing', 2, None, 'continuing'),
              ('Wrapping it up', 2, None, 'wrapping-it-up'),
              ('Summary of course', 2, None, 'summary-of-course'),
              ('What? Me worry? No final exam in this course!',
               2,
               None,
               'what-me-worry-no-final-exam-in-this-course'),
              ('What is the link between Artificial Intelligence and Machine '
               'Learning and some general Remarks',
               2,
               None,
               'what-is-the-link-between-artificial-intelligence-and-machine-learning-and-some-general-remarks'),
              ('Going back to the beginning of the semester',
               2,
               None,
               'going-back-to-the-beginning-of-the-semester'),
              ('Not so sharp distinctions',
               2,
               None,
               'not-so-sharp-distinctions'),
              ('Topics we have covered this year',
               2,
               None,
               'topics-we-have-covered-this-year'),
              ('Statistical analysis and optimization of data',
               2,
               None,
               'statistical-analysis-and-optimization-of-data'),
              ('Machine learning', 2, None, 'machine-learning'),
              ('Learning outcomes and overarching aims of this course',
               2,
               None,
               'learning-outcomes-and-overarching-aims-of-this-course'),
              ('Perspective on Machine Learning',
               2,
               None,
               'perspective-on-machine-learning'),
              ('Machine Learning Research',
               2,
               None,
               'machine-learning-research'),
              ('Starting your Machine Learning Project',
               2,
               None,
               'starting-your-machine-learning-project'),
              ('Choose a Model and Algorithm',
               2,
               None,
               'choose-a-model-and-algorithm'),
              ('Preparing Your Data', 2, None, 'preparing-your-data'),
              ('Which Activation and Weights to Choose in Neural Networks',
               2,
               None,
               'which-activation-and-weights-to-choose-in-neural-networks'),
              ('Optimization Methods and Hyperparameters',
               2,
               None,
               'optimization-methods-and-hyperparameters'),
              ('Resampling', 2, None, 'resampling'),
              ('Other courses on Data science and Machine Learning  at UiO',
               2,
               None,
               'other-courses-on-data-science-and-machine-learning-at-uio'),
              ('Additional courses of interest',
               2,
               None,
               'additional-courses-of-interest'),
              ("What's the future like?", 2, None, 'what-s-the-future-like'),
              ('Types of Machine Learning, a repetition',
               2,
               None,
               'types-of-machine-learning-a-repetition'),
              ('Why Boltzmann machines?', 2, None, 'why-boltzmann-machines'),
              ('Boltzmann Machines', 2, None, 'boltzmann-machines'),
              ('Some similarities and differences from DNNs',
               2,
               None,
               'some-similarities-and-differences-from-dnns'),
              ('Boltzmann machines (BM)', 2, None, 'boltzmann-machines-bm'),
              ('A standard BM setup', 2, None, 'a-standard-bm-setup'),
              ('The structure of the RBM network',
               2,
               None,
               'the-structure-of-the-rbm-network'),
              ('The network', 2, None, 'the-network'),
              ('Goals', 2, None, 'goals'),
              ('Joint distribution', 2, None, 'joint-distribution'),
              ('Network Elements, the energy function',
               2,
               None,
               'network-elements-the-energy-function'),
              ('Defining different types of RBMs',
               2,
               None,
               'defining-different-types-of-rbms'),
              ('More about RBMs', 2, None, 'more-about-rbms'),
              ('Autoencoders: Overarching view',
               2,
               None,
               'autoencoders-overarching-view'),
              ('Bayesian Machine Learning',
               2,
               None,
               'bayesian-machine-learning'),
              ('Reinforcement Learning', 2, None, 'reinforcement-learning'),
              ('Transfer learning', 2, None, 'transfer-learning'),
              ('Adversarial learning', 2, None, 'adversarial-learning'),
              ('Dual learning', 2, None, 'dual-learning'),
              ('Distributed machine learning',
               2,
               None,
               'distributed-machine-learning'),
              ('Meta learning', 2, None, 'meta-learning'),
              ('The Challenges Facing Machine Learning',
               2,
               None,
               'the-challenges-facing-machine-learning'),
              ('Explainable machine learning',
               2,
               None,
               'explainable-machine-learning'),
              ('Scientific Machine Learning',
               2,
               None,
               'scientific-machine-learning'),
              ('Quantum machine learning', 2, None, 'quantum-machine-learning'),
              ('Quantum machine learning algorithms based on linear algebra',
               2,
               None,
               'quantum-machine-learning-algorithms-based-on-linear-algebra'),
              ('Quantum reinforcement learning',
               2,
               None,
               'quantum-reinforcement-learning'),
              ('Quantum deep learning', 2, None, 'quantum-deep-learning'),
              ('Social machine learning', 2, None, 'social-machine-learning'),
              ('The last words?', 2, None, 'the-last-words'),
              ('AI/ML and some statements you may have heard (and what do they '
               'mean?)',
               2,
               None,
               'ai-ml-and-some-statements-you-may-have-heard-and-what-do-they-mean'),
              ('Best wishes to you all and thanks so much for your heroic '
               'efforts this semester',
               2,
               None,
               'best-wishes-to-you-all-and-thanks-so-much-for-your-heroic-efforts-this-semester')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week47-bs.html">Week 47: Unsupervised learning (PCA and Clustering)  and Summary of Course</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week47-bs001.html#overview-of-week-47" style="font-size: 80%;"><b>Overview of week 47</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs002.html#basic-ideas-of-the-principal-component-analysis-pca" style="font-size: 80%;"><b>Basic ideas of the Principal Component Analysis (PCA)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs003.html#introducing-the-covariance-and-correlation-functions" style="font-size: 80%;"><b>Introducing the Covariance and Correlation functions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs004.html#more-on-the-covariance" style="font-size: 80%;"><b>More on the covariance</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs005.html#reminding-ourselves-about-linear-regression" style="font-size: 80%;"><b>Reminding ourselves about Linear Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs006.html#simple-example" style="font-size: 80%;"><b>Simple Example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs007.html#the-correlation-matrix" style="font-size: 80%;"><b>The Correlation Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs008.html#numpy-functionality" style="font-size: 80%;"><b>Numpy Functionality</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs009.html#correlation-matrix-again" style="font-size: 80%;"><b>Correlation Matrix again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs010.html#using-pandas" style="font-size: 80%;"><b>Using Pandas</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs011.html#and-then-the-franke-function" style="font-size: 80%;"><b>And then the Franke Function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs012.html#links-with-the-design-matrix" style="font-size: 80%;"><b>Links with the Design Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs013.html#computing-the-expectation-values" style="font-size: 80%;"><b>Computing the Expectation Values</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs014.html#towards-the-pca-theorem" style="font-size: 80%;"><b>Towards the PCA theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs015.html#more-on-the-pca-theorem" style="font-size: 80%;"><b>More on the PCA Theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs016.html#a-kind-of-bird-s-view-on-pca" style="font-size: 80%;"><b>A kind of Bird's view  on PCA</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs017.html#writing-our-own-pca-code" style="font-size: 80%;"><b>Writing our own PCA code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs018.html#implementing-it" style="font-size: 80%;"><b>Implementing it</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs019.html#first-step" style="font-size: 80%;"><b>First Step</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs020.html#scaling" style="font-size: 80%;"><b>Scaling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs021.html#centered-data" style="font-size: 80%;"><b>Centered Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs022.html#exploring" style="font-size: 80%;"><b>Exploring</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs023.html#diagonalize-the-sample-covariance-matrix-to-obtain-the-principal-components" style="font-size: 80%;"><b>Diagonalize the sample covariance matrix to obtain the principal components</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs024.html#collecting-all-steps" style="font-size: 80%;"><b>Collecting all Steps</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs025.html#classical-pca-theorem" style="font-size: 80%;"><b>Classical PCA Theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs026.html#the-pca-theorem" style="font-size: 80%;"><b>The PCA Theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs027.html#geometric-interpretation-and-link-with-singular-value-decomposition" style="font-size: 80%;"><b>Geometric Interpretation and link with Singular Value Decomposition</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs028.html#pca-and-scikit-learn" style="font-size: 80%;"><b>PCA and scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs029.html#back-to-the-cancer-data" style="font-size: 80%;"><b>Back to the Cancer Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs030.html#incremental-pca" style="font-size: 80%;"><b>Incremental PCA</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs030.html#randomized-pca" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Randomized PCA</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs030.html#kernel-pca" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Kernel PCA</a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs031.html#other-techniques" style="font-size: 80%;"><b>Other techniques</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs032.html#clustering-and-unsupervised-learning" style="font-size: 80%;"><b>Clustering and Unsupervised Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs033.html#basic-idea-of-the-k-means-clustering-algorithm" style="font-size: 80%;"><b>Basic Idea of the \( k \)-means Clustering Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs034.html#the-k-means-algorithm" style="font-size: 80%;"><b>The \( k \)-means Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs035.html#basic-math-of-the-k-means-algorithm" style="font-size: 80%;"><b>Basic Math of the \( k \)-means Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs036.html#within-cluster-point-scatter" style="font-size: 80%;"><b>Within Cluster Point Scatter</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs037.html#more-details" style="font-size: 80%;"><b>More Details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs038.html#total-cluster-variance" style="font-size: 80%;"><b>Total Cluster Variance</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs039.html#the-k-means-clustering-algorithm" style="font-size: 80%;"><b>The \( k \)-means Clustering Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs040.html#summarizing" style="font-size: 80%;"><b>Summarizing</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs041.html#writing-our-own-code-the-data-set" style="font-size: 80%;"><b>Writing our own Code, the Data Set</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs042.html#implementing-the-k-means-algorithm" style="font-size: 80%;"><b>Implementing the \( k \)-means Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs043.html#plotting" style="font-size: 80%;"><b>Plotting</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs044.html#continuing" style="font-size: 80%;"><b>Continuing</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs045.html#wrapping-it-up" style="font-size: 80%;"><b>Wrapping it up</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs046.html#summary-of-course" style="font-size: 80%;"><b>Summary of course</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs047.html#what-me-worry-no-final-exam-in-this-course" style="font-size: 80%;"><b>What? Me worry? No final exam in this course!</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs048.html#what-is-the-link-between-artificial-intelligence-and-machine-learning-and-some-general-remarks" style="font-size: 80%;"><b>What is the link between Artificial Intelligence and Machine Learning and some general Remarks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs049.html#going-back-to-the-beginning-of-the-semester" style="font-size: 80%;"><b>Going back to the beginning of the semester</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs050.html#not-so-sharp-distinctions" style="font-size: 80%;"><b>Not so sharp distinctions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs051.html#topics-we-have-covered-this-year" style="font-size: 80%;"><b>Topics we have covered this year</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs052.html#statistical-analysis-and-optimization-of-data" style="font-size: 80%;"><b>Statistical analysis and optimization of data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs053.html#machine-learning" style="font-size: 80%;"><b>Machine learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs054.html#learning-outcomes-and-overarching-aims-of-this-course" style="font-size: 80%;"><b>Learning outcomes and overarching aims of this course</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs055.html#perspective-on-machine-learning" style="font-size: 80%;"><b>Perspective on Machine Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs056.html#machine-learning-research" style="font-size: 80%;"><b>Machine Learning Research</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs057.html#starting-your-machine-learning-project" style="font-size: 80%;"><b>Starting your Machine Learning Project</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs058.html#choose-a-model-and-algorithm" style="font-size: 80%;"><b>Choose a Model and Algorithm</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs059.html#preparing-your-data" style="font-size: 80%;"><b>Preparing Your Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs060.html#which-activation-and-weights-to-choose-in-neural-networks" style="font-size: 80%;"><b>Which Activation and Weights to Choose in Neural Networks</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs061.html#optimization-methods-and-hyperparameters" style="font-size: 80%;"><b>Optimization Methods and Hyperparameters</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs062.html#resampling" style="font-size: 80%;"><b>Resampling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs063.html#other-courses-on-data-science-and-machine-learning-at-uio" style="font-size: 80%;"><b>Other courses on Data science and Machine Learning  at UiO</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs064.html#additional-courses-of-interest" style="font-size: 80%;"><b>Additional courses of interest</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs065.html#what-s-the-future-like" style="font-size: 80%;"><b>What's the future like?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs066.html#types-of-machine-learning-a-repetition" style="font-size: 80%;"><b>Types of Machine Learning, a repetition</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs067.html#why-boltzmann-machines" style="font-size: 80%;"><b>Why Boltzmann machines?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs068.html#boltzmann-machines" style="font-size: 80%;"><b>Boltzmann Machines</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs069.html#some-similarities-and-differences-from-dnns" style="font-size: 80%;"><b>Some similarities and differences from DNNs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs070.html#boltzmann-machines-bm" style="font-size: 80%;"><b>Boltzmann machines (BM)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs071.html#a-standard-bm-setup" style="font-size: 80%;"><b>A standard BM setup</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs072.html#the-structure-of-the-rbm-network" style="font-size: 80%;"><b>The structure of the RBM network</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs073.html#the-network" style="font-size: 80%;"><b>The network</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs074.html#goals" style="font-size: 80%;"><b>Goals</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs075.html#joint-distribution" style="font-size: 80%;"><b>Joint distribution</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs076.html#network-elements-the-energy-function" style="font-size: 80%;"><b>Network Elements, the energy function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs077.html#defining-different-types-of-rbms" style="font-size: 80%;"><b>Defining different types of RBMs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs078.html#more-about-rbms" style="font-size: 80%;"><b>More about RBMs</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs079.html#autoencoders-overarching-view" style="font-size: 80%;"><b>Autoencoders: Overarching view</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs080.html#bayesian-machine-learning" style="font-size: 80%;"><b>Bayesian Machine Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs081.html#reinforcement-learning" style="font-size: 80%;"><b>Reinforcement Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs082.html#transfer-learning" style="font-size: 80%;"><b>Transfer learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs083.html#adversarial-learning" style="font-size: 80%;"><b>Adversarial learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs084.html#dual-learning" style="font-size: 80%;"><b>Dual learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs085.html#distributed-machine-learning" style="font-size: 80%;"><b>Distributed machine learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs086.html#meta-learning" style="font-size: 80%;"><b>Meta learning</b></a></li>
     <!-- navigation toc: --> <li><a href="#the-challenges-facing-machine-learning" style="font-size: 80%;"><b>The Challenges Facing Machine Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs088.html#explainable-machine-learning" style="font-size: 80%;"><b>Explainable machine learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs089.html#scientific-machine-learning" style="font-size: 80%;"><b>Scientific Machine Learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs090.html#quantum-machine-learning" style="font-size: 80%;"><b>Quantum machine learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs091.html#quantum-machine-learning-algorithms-based-on-linear-algebra" style="font-size: 80%;"><b>Quantum machine learning algorithms based on linear algebra</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs092.html#quantum-reinforcement-learning" style="font-size: 80%;"><b>Quantum reinforcement learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs093.html#quantum-deep-learning" style="font-size: 80%;"><b>Quantum deep learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs094.html#social-machine-learning" style="font-size: 80%;"><b>Social machine learning</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs095.html#the-last-words" style="font-size: 80%;"><b>The last words?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs096.html#ai-ml-and-some-statements-you-may-have-heard-and-what-do-they-mean" style="font-size: 80%;"><b>AI/ML and some statements you may have heard (and what do they mean?)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week47-bs097.html#best-wishes-to-you-all-and-thanks-so-much-for-your-heroic-efforts-this-semester" style="font-size: 80%;"><b>Best wishes to you all and thanks so much for your heroic efforts this semester</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0087"></a>
<!-- !split -->
<h2 id="the-challenges-facing-machine-learning" class="anchor">The Challenges Facing Machine Learning </h2>

<p>While there has been much progress in machine learning, there are also challenges.</p>

<p>For example, the mainstream machine learning technologies are
black-box approaches, making us concerned about their potential
risks. To tackle this challenge, we may want to make machine learning
more explainable and controllable. As another example, the
computational complexity of machine learning algorithms is usually
very high and we may want to invent lightweight algorithms or
implementations. Furthermore, in many domains such as physics,
chemistry, biology, and social sciences, people usually seek elegantly
simple equations (e.g., the Schr&#246;dinger equation) to uncover the
underlying laws behind various phenomena. In the field of machine
learning, can we reveal simple laws instead of designing more complex
models for data fitting? Although there are many challenges, we are
still very optimistic about the future of machine learning. As we look
forward to the future, here are what we think the research hotspots in
the next ten years will be.
</p>

<p>See the article on <a href="https://www.frontiersin.org/articles/10.3389/frai.2020.00025/full" target="_self">Discovery of Physics From Data: Universal Laws and Discrepancies</a></p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week47-bs086.html">&laquo;</a></li>
  <li><a href="._week47-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week47-bs079.html">80</a></li>
  <li><a href="._week47-bs080.html">81</a></li>
  <li><a href="._week47-bs081.html">82</a></li>
  <li><a href="._week47-bs082.html">83</a></li>
  <li><a href="._week47-bs083.html">84</a></li>
  <li><a href="._week47-bs084.html">85</a></li>
  <li><a href="._week47-bs085.html">86</a></li>
  <li><a href="._week47-bs086.html">87</a></li>
  <li class="active"><a href="._week47-bs087.html">88</a></li>
  <li><a href="._week47-bs088.html">89</a></li>
  <li><a href="._week47-bs089.html">90</a></li>
  <li><a href="._week47-bs090.html">91</a></li>
  <li><a href="._week47-bs091.html">92</a></li>
  <li><a href="._week47-bs092.html">93</a></li>
  <li><a href="._week47-bs093.html">94</a></li>
  <li><a href="._week47-bs094.html">95</a></li>
  <li><a href="._week47-bs095.html">96</a></li>
  <li><a href="._week47-bs096.html">97</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week47-bs097.html">98</a></li>
  <li><a href="._week47-bs088.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

